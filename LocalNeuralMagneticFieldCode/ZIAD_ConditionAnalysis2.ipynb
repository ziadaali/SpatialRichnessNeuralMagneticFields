{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024847c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import copy\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0004eb",
   "metadata": {},
   "source": [
    "### Generate Recording\n",
    "- Create a recording from a single trace of specified time duration (Poisson spike distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721f62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_recording(templates, dur, rate, dt):\n",
    "    \n",
    "    dt = dt / 1000 # Convert to ms\n",
    "    timesteps = int(dur/dt)\n",
    "    spike_prob = rate * dt\n",
    "    \n",
    "    spike_train = np.random.uniform(size=(timesteps, 1)) < spike_prob\n",
    "    spike_idxs = np.where(spike_train == True)[0]\n",
    "    \n",
    "    template_dur = np.shape(templates)[-1]\n",
    "    \n",
    "    # Add all spikes into recording\n",
    "    num_elecs = np.shape(templates)[-2]\n",
    "    num_fields = np.shape(templates)[0]\n",
    "    \n",
    "    recording = np.zeros((num_fields, num_elecs, timesteps))\n",
    "    \n",
    "    for i in range(len(spike_idxs)):\n",
    "        spike_idx = spike_idxs[i]\n",
    "        if spike_idx + template_dur < timesteps:\n",
    "            recording[:, :, spike_idx:spike_idx+template_dur] = templates\n",
    "    \n",
    "    return recording"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80bbf58",
   "metadata": {},
   "source": [
    "### Generate All Recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2223f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_all_recordings(fields, num_temps, dur, rate, dt):\n",
    "\n",
    "    temp_indices = np.random.choice(len(fields[0]), num_temps, replace=False)\n",
    "\n",
    "    recordings = []\n",
    "    for idx in temp_indices:\n",
    "        recording = gen_recording(fields[:, idx], dur, rate, dt)\n",
    "        recordings.append(recording)\n",
    "\n",
    "    recordings = np.array(recordings)\n",
    "    \n",
    "    return recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc73430",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b04e917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V:  (1800, 100, 224)\n",
      "Bx:  (1800, 100, 224)\n",
      "By:  (1800, 100, 224)\n",
      "Bz:  (1800, 100, 224)\n",
      "Locations:  (1800, 3)\n",
      "Rotations:  (1800, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get all templates from files\n",
    "\n",
    "folder_name = 'ziad_mearec_templates/'\n",
    "mea_name = '100MEA75'\n",
    "\n",
    "#file_name = 'mag_templates_flattened_x15_cell2_rotate_n50_100MEA75.npy'\n",
    "file_name = f'mag_templates_flattened_5-25bound_0-2cells_n300_{mea_name}.npy'\n",
    "#file_name = 'mag_templates_flattened_noise_cells2-3_ylim36.0_zlim[-535.5, 535.5]_Neuropixels-128.npy'\n",
    "#file_name = 'mag_templates_flattened_noise_cells2-3_xlim[60, 100]_ylim[60, 100]_zlim[-535.5, 535.5]_Neuropixels-128.npy'\n",
    "\n",
    "#file_name = 'mag_templates_flattened_5-25bound_2-4cells_n300_Neuropixels-128.npy'\n",
    "#file_name = 'mag_templates_flattened_5-25bound_2-4cells_n300_Neuropixels-128.npy'\n",
    "#file_name = f'mag_templates_flattened_5-25bound_0-2cells_n300_Ziad_Custom_-2_100MEA75_Ex.npy'\n",
    "\n",
    "with open(folder_name + file_name, 'rb') as f:\n",
    "    v = np.load(f)[:, :, :]\n",
    "    bx = np.load(f)[:, :, :]\n",
    "    by = np.load(f)[:, :, :]\n",
    "    bz = np.load(f)[:, :, :]\n",
    "    locs = np.load(f)\n",
    "    rots = np.load(f)\n",
    "\n",
    "addl_files = []\n",
    "addl_files = [f'mag_templates_flattened_5-25bound_2-4cells_n300_{mea_name}.npy',\n",
    "              f'mag_templates_flattened_5-25bound_4-6cells_n300_{mea_name}.npy']\n",
    "\n",
    "# addl_files = ['mag_templates_flattened_5-25bound_2-4cells_n300_Ziad_Custom_-2_100MEA75_Ex.npy',\n",
    "#               'mag_templates_flattened_5-25bound_4-6cells_n300_Ziad_Custom_-2_100MEA75_Ex.npy']\n",
    "\n",
    "for file in addl_files:\n",
    "    with open(folder_name + file, 'rb') as f:\n",
    "        v2 = np.load(f)[:, :, :]\n",
    "        bx2 = np.load(f)[:, :, :]\n",
    "        by2 = np.load(f)[:, :, :]\n",
    "        bz2 = np.load(f)[:, :, :]\n",
    "        locs2 = np.load(f)\n",
    "        rots2 = np.load(f) \n",
    "\n",
    "        v = np.concatenate((v, v2), axis=0)\n",
    "        bx = np.concatenate((bx, bx2), axis=0)\n",
    "        by = np.concatenate((by, by2), axis=0)\n",
    "        bz = np.concatenate((bz, bz2), axis=0)\n",
    "        locs = np.concatenate((locs, locs2), axis=0)\n",
    "        rots = np.concatenate((rots, rots2), axis=0)\n",
    "\n",
    "fields = np.array([v, bx, by, bz])\n",
    "print(\"V: \", np.shape(v))\n",
    "print(\"Bx: \", np.shape(bx))\n",
    "print(\"By: \", np.shape(by))\n",
    "print(\"Bz: \", np.shape(bz))\n",
    "print(\"Locations: \", np.shape(locs))\n",
    "print(\"Rotations: \", np.shape(rots))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1645b8",
   "metadata": {},
   "source": [
    "### Condition Number Analysis\n",
    "- all_temps: Array of number of cells (transmitters) to include (randomly sample) in analysis\n",
    "- n_per_cell: Number of templates per cell (fixed)\n",
    "- fields_to_run: Maximum value of 7 - 0=V, 1=Bx, 2=By, 3=Bz, 4=BxByBz, 5=ByBz, 6=VBx; so value of 3 runs V, Bx, and By\n",
    "- cell_indices: Which cells to run (cells 2 and 3 are the best for B-fields)\n",
    "- generate_recordings: If it is enabled, the H matrix is populated with recordings; otherwise, it uses templates\n",
    "- dur: Duration of simulated recording\n",
    "- rate: Poisson average spiking rate for recording generation\n",
    "- dt: Timestep of simulation (fixed)\n",
    "\n",
    "- Outputs:\n",
    "    - Prints condition number for each iteration of each field\n",
    "    - Averages condition numbers together at the end of the sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc9c6efa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.396849540863267 \t 3.7352446306534888 \t 30 \t7.479887417154441 \t 1.3637339353478646 \t 30 \t18.463356544707942 \t 3.7937236286470997 \t 30 \t23.358386465399104 \t 6.425513378508477 \t 30 \t6.654426272606913 \t 1.5491729587420522 \t 30 \t10.841289644957554 \t 2.1331979301569053 \t 30 \t5.561197175887508 \t 1.0168028141139849 \t 30 \t\n",
      "30.649278671030068 \t 6.897604594410327 \t 30 \t14.444843127074767 \t 2.7922469473639637 \t 30 \t34.5380880682776 \t 9.153186068590394 \t 30 \t40.636261377579 \t 8.183418397427845 \t 30 \t10.143908945232887 \t 1.8573923051988108 \t 30 \t17.97027002535226 \t 3.6030096090871155 \t 30 \t10.394892871668693 \t 2.0408124824835143 \t 30 \t\n"
     ]
    }
   ],
   "source": [
    "#all_temps = [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]\n",
    "all_temps = [50, 113]\n",
    "n_per_cell = 300\n",
    "fields_to_run = 7\n",
    "field_labels = ['V', 'Bx', 'By', 'Bz', 'BxByBz', 'ByBz', 'VBx']\n",
    "\n",
    "all_s = []\n",
    "\n",
    "generate_recordings = False\n",
    "dur = 1        # Duration (s) of fake recording             \n",
    "rate = 10      # Spiking rate (Hz) for Poisson process\n",
    "dt = 0.03125   # dt of simulation\n",
    "\n",
    "verbose = False\n",
    "\n",
    "for num_temps in all_temps:\n",
    "    cell_indices = [2, 3]\n",
    "    #cell_indices = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "    iters = 30\n",
    "\n",
    "    # Store all condition numbers\n",
    "    conds = np.zeros((fields_to_run, iters))\n",
    "    \n",
    "    # Store all singular values\n",
    "    s_vals = np.zeros((fields_to_run, iters, num_temps))\n",
    "    \n",
    "    # Create H matrix from flattened recordings for each field\n",
    "    for j in range(iters):\n",
    "        if verbose:\n",
    "            print(\"Iteration:\", j)\n",
    "        \n",
    "        # Get fields corresponding to specified cells\n",
    "        num_fields = np.shape(fields)[0]\n",
    "        total_num_templates = len(cell_indices)*n_per_cell\n",
    "        num_elecs = np.shape(fields)[2]\n",
    "        num_tsteps = np.shape(fields)[3]\n",
    "\n",
    "        # Create array of only templates from specified cells (all field types)\n",
    "        sub_fields = np.zeros((num_fields, total_num_templates, num_elecs, num_tsteps))\n",
    "        for n, cell_idx in enumerate(cell_indices):\n",
    "            sub_fields[:, n*n_per_cell:(n+1)*n_per_cell] = fields[:, cell_idx*n_per_cell:(cell_idx+1)*n_per_cell]\n",
    "\n",
    "        # Select num_temps random templates and store in templates\n",
    "        idxs = np.random.choice(len(sub_fields[0]), num_temps, replace=False)\n",
    "        templates = sub_fields[:, idxs]\n",
    "#         if verbose:\n",
    "#             print(np.shape(templates))\n",
    "        \n",
    "        if generate_recordings == True:\n",
    "            templates = gen_all_recordings(templates, num_temps, dur, rate, dt)\n",
    "            templates = np.transpose(templates, (1, 0, 2, 3))\n",
    "            print(\"Templates new shape: \", np.shape(templates))\n",
    "            \n",
    "        # Flatten electrode data - H has shape (num_temps x (timesteps * num_electrodes))\n",
    "        for i in range(fields_to_run):\n",
    "            \n",
    "            # Run BxByBz\n",
    "            if i == 4:\n",
    "                H = np.transpose(templates[1:4], (1, 0, 2, 3))\n",
    "                H = H.reshape((len(templates[0]), -1))\n",
    "            # Run ByBz\n",
    "            elif i == 5:\n",
    "                H = np.transpose(templates[2:4], (1, 0, 2, 3))\n",
    "                H = H.reshape((len(templates[0]), -1))\n",
    "            # Run VBx\n",
    "            elif i == 6:\n",
    "                H = np.transpose(templates[0:2], (1, 0, 2, 3))\n",
    "                #print(\"H shape 1: \", np.shape(H))\n",
    "                H[:, 0] = H[:, 0] / np.linalg.norm(H[:, 0])\n",
    "                H[:, 1] = H[:, 1] / np.linalg.norm(H[:, 1])\n",
    "                H = H.reshape((len(templates[0]), -1))\n",
    "            # Run single field\n",
    "            else:\n",
    "                H = templates[i].reshape((len(templates[0]), -1))\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"H shape:\", np.shape(H))\n",
    "            \n",
    "            H = np.matrix(H / np.linalg.norm(H))\n",
    "            cov = H * H.getH()\n",
    "            #cov = np.cov(H)\n",
    "            \n",
    "            u, s, vh = np.linalg.svd(cov)\n",
    "            s = np.sqrt(s)\n",
    "            cond = s[0]/s[-1]\n",
    "            if verbose:\n",
    "                print(field_labels[i], \":\", cond)\n",
    "\n",
    "            conds[i, j] = cond\n",
    "            s_vals[i, j] = s\n",
    "        if verbose:\n",
    "            print(\"\")\n",
    "\n",
    "    means = np.mean(conds, axis=1)\n",
    "    stds = np.std(conds, axis=1)\n",
    "    if verbose == True:\n",
    "        print(\"Field \\t Mean Condition Number \\t Std\")\n",
    "        for q in range(len(means)):\n",
    "            print(field_labels[q], '\\t', means[q], '\\t', stds[q])\n",
    "\n",
    "        print()\n",
    "    for q in range(len(means)):\n",
    "        print(means[q], '\\t', stds[q], '\\t', str(iters), '\\t', end=\"\")\n",
    "    print()\n",
    "    all_s.append(s_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f786a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.275069270282984e-11\n"
     ]
    }
   ],
   "source": [
    "a = np.random.random((20, 100, 300))\n",
    "\n",
    "b = a*1.0\n",
    "c = a*1.0\n",
    "b[:, :, 150:] = 0\n",
    "c[:, :, :150] = 0\n",
    "\n",
    "a = a.reshape((20, -1))\n",
    "b = b.reshape((20, -1))\n",
    "c = c.reshape((20, -1))\n",
    "\n",
    "aH = np.dot(a, a.T)\n",
    "qH = np.dot(b, b.T) + np.dot(c, c.T)\n",
    "\n",
    "print(np.sum(aH-qH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25bffe99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(dur/dt*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565078fb",
   "metadata": {},
   "source": [
    "### Singular Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ef767",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_s = np.mean(all_s[0][0], axis=0)\n",
    "plt.plot(np.log10(mean_s))\n",
    "mean_s = np.mean(all_s[0][1], axis=0)\n",
    "plt.plot(np.log10(mean_s))\n",
    "mean_s = np.mean(all_s[0][2], axis=0)\n",
    "plt.plot(np.log10(mean_s))\n",
    "mean_s = np.mean(all_s[0][3], axis=0)\n",
    "plt.plot(np.log10(mean_s))\n",
    "\n",
    "plt.legend(['V', 'Bx', 'By', 'Bz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af249ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 3\n",
    "vals = np.log10(all_s[0][idx])\n",
    "means = np.mean(vals, axis=0)\n",
    "stds = np.std(vals, axis=0)\n",
    "\n",
    "for i in range(len(means)):\n",
    "    print(means[i], '\\t', stds[i], '\\t', str(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.random.random((10, 30))\n",
    "H = np.matrix(H / np.linalg.norm(H))\n",
    "cov = H * H.getH()\n",
    "#cov = np.cov(H)\n",
    "u, s, vh = np.linalg.svd(H)\n",
    "u, sCov, vh = np.linalg.svd(cov)\n",
    "\n",
    "print(\"Singular Values H Matrix: \", s, '\\n')\n",
    "print(\"Singular Values Covariance Matrix: \", sCov, '\\n')\n",
    "print(\"Sqrt Singular Values Covariance Matrix: \", np.sqrt(sCov), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d55477ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((10, 20))\n",
    "a = np.matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e630e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.96490076 1.95017604 1.71541091 1.58259562 1.34856072 1.24987526\n",
      " 0.96036467 0.81450536 0.72654359 0.48972336]\n"
     ]
    }
   ],
   "source": [
    "u, s, vh = np.linalg.svd(a)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b02747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = a * a.getH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35687475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48.50984257  3.80318657  2.94263458  2.5046089   1.81861603  1.56218816\n",
      "  0.92230031  0.66341898  0.52786558  0.23982897]\n",
      "[6.96490076 1.95017604 1.71541091 1.58259562 1.34856072 1.24987526\n",
      " 0.96036467 0.81450536 0.72654359 0.48972336]\n"
     ]
    }
   ],
   "source": [
    "u, s, vh = np.linalg.svd(cov)\n",
    "print(s)\n",
    "print(np.sqrt(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87d5a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = a - np.mean(a)\n",
    "cov = a2 * a2.getH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0b86c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.95533684 3.14185803 2.73311264 2.3142591  1.7662542  1.32644173\n",
      " 0.91103641 0.66629506 0.36424103 0.18069747]\n",
      "[1.98880287 1.77252871 1.65321282 1.52126891 1.32900497 1.15171252\n",
      " 0.95448227 0.81626899 0.60352385 0.42508525]\n"
     ]
    }
   ],
   "source": [
    "u, s, vh = np.linalg.svd(cov)\n",
    "print(s)\n",
    "print(np.sqrt(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2935d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
